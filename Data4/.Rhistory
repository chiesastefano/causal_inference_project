head(t_wages)
t_wages <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\wages_pps.csv")
t_productivity <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\productivity_per_person.csv")
t_economic_values <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\economic_values_per_industry.csv")
t_wages <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\wages_pps.csv")
t_productivity <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\productivity_per_person.csv")
t_economic_values <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\economic_values_per_industry.csv")
t_wages <- read.csv("C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\wages_pps.csv")
# Display the first few rows of t_wages
table(t_wages)
# Corrected file paths using double backslashes (\\)
t_wages <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\wages_pps.csv")
t_productivity <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\productivity_per_person.csv")
t_economic_values <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\economic_values_per_industry.csv")
t_bankrupcy_and_registration_index <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\bankrupcy_and_registration_index_percentage_change.csv")
# Display the first few rows of t_wages
table(t_wages)
# Display the first few rows of t_wages
head(t_wages)
View(t_wages)
View(t_economic_values)
#t_wages_2 <- subset(t_wages, select = -c(DATAFLOW, LAST.UPDATE, freq, currency, ))
names(t_wages)
t_wages_2 <- subset(t_wages, select = -c("DATAFLOW", "LAST.UPDATE", "freq", "currency", "unit", "sizeclas", "OBS_FLAG"))
t_wages_2 <- subset(t_wages, select = -c(DATAFLOW, LAST.UPDATE, freq, currency, unit, sizeclas, OBS_FLAG))
names(t_wages)
View(t_wages_2)
names(t_wages_2)[names(t_wages_2) == "OBS_VALUE"] <- "Wages and salaries"
View(t_wages_2)
names(t_wages_2)[names(t_wages_2) == "TIME_PERIOD"] <- "Year"
t_wages_2 <- subset(t_wages, select = -c(Icstruct))
t_wages_2 <- subset(t_wages, select = -c(lcstruct))
names(t_wages_2)[names(t_wages_2) == "geo"] <- "Country"
View(t_wages_2)
t_wages_2 <- subset(t_wages_2, select = -c(lcstruct))
# Corrected file paths using double backslashes (\\)
t_wages <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\wages_pps.csv")
t_productivity <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\productivity_per_person.csv")
t_economic_values <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\economic_values_per_industry.csv")
t_bankrupcy_and_registration_index <- read.csv("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\bankrupcy_and_registration_index_percentage_change.csv")
# Display the first few rows of t_wages
head(t_wages)
t_wages_2 <- subset(t_wages, select = -c(DATAFLOW, LAST.UPDATE, freq, currency, unit, sizeclas, OBS_FLAG))
names(t_wages_2)[names(t_wages_2) == "OBS_VALUE"] <- "Wages and salaries"
names(t_wages_2)[names(t_wages_2) == "TIME_PERIOD"] <- "Year"
names(t_wages_2)[names(t_wages_2) == "geo"] <- "Country"
t_wages_2 <- subset(t_wages_2, select = -c(lcstruct))
View(t_wages_2)
View(t_productivity)
t_productivity_2 <- subset(t_productivity, select = (nace_r2, geo, TIME_PERIOD, OBS_VALUE))
t_productivity_2 <- subset(t_productivity, select = c(nace_r2, geo, TIME_PERIOD, OBS_VALUE))
names(t_productivity_2)[names(t_productivity_2) == "OBS_VALUE"] <- "Real labour productivity per person"
names(t_productivity_2)[names(t_productivity_2) == "TIME_PERIOD"] <- "Year"
names(t_productivity_2)[names(t_productivity_2) == "geo"] <- "Country"
View(t_productivity_2)
View(t_bankrupcy_and_registration_index)
t_bankrupcy_and_registration_index_2 <- subset(t_productivity, select = c(nace_r2, geo, TIME_PERIOD, OBS_VALUE, indic_bt))
View(t_bankrupcy_and_registration_index)
names(t_bankrupcy_and_registration_index)
t_bankrupcy_and_registration_index_2 <- subset(t_productivity, select = c(nace_r2, geo, TIME_PERIOD, OBS_VALUE, indic_bt))
t_bankrupcy_and_registration_index_2 <- subset(t_bankrupcy_and_registration_index, select = c(nace_r2, geo, TIME_PERIOD, OBS_VALUE, indic_bt))
_
names(t_bankrupcy_and_registration_index_2)[names(t_bankrupcy_and_registration_index_2) == "TIME_PERIOD"] <- "Year"
names(t_bankrupcy_and_registration_index_2)[names(t_bankrupcy_and_registration_index_2) == "geo"] <- "Country"
# Filter rows with "Bankruptcy declarations"
t_bankruptcy <- subset(t_bankrupcy_and_registration_index_2, indic_bt == "Bankruptcy declarations")
# Filter rows with "Registrations"
t_registrations <- subset(t_bankrupcy_and_registration_index_2, indic_bt == "Registrations")
View(t_bankruptcy)
names(t_bankrupcy)[names(t_bankrupcy) == "OBS_VALUE"] <- "Bankruptcy declarations Index"
View(t_bankruptcy)
names(t_bankrupcy)[names(t_bankrupcy) == "OBS_VALUE"] <- "Bankruptcy declarations Index"
# Filter rows with "Bankruptcy declarations"
t_bankruptcy <- subset(t_bankrupcy_and_registration_index_2, indic_bt == "Bankruptcy declarations")
# Filter rows with "Registrations"
t_registrations <- subset(t_bankrupcy_and_registration_index_2, indic_bt == "Registrations")
names(t_bankrupcy)[names(t_bankrupcy) == "OBS_VALUE"] <- "Bankruptcy declarations Index"
names(t_bankruptcy)[names(t_bankruptcy) == "OBS_VALUE"] <- "Bankruptcy declarations Index"
View(t_bankruptcy)
t_bankruptcy <- subset(t_bankruptcy, select = -c(indic_bt))
View(t_registrations)
names(t_registrations)[names(t_registrations) == "OBS_VALUE"] <- "Registrations"
t_registrations <- subset(t_registrations, select = -c(indic_bt))
View(t_economic_values)
# Get unique values in the 'na_item' column
unique_values <- unique(t_economic_values$na_item)
# Create a list to store the resulting data frames
list_of_tables <- lapply(unique_values, function(value) {
# Filter the rows where 'na_item' equals the current value
table <- subset(t_economic_values, na_item == value)
# Rename the 'OBS_VALUE' column to the current 'na_item' value
colnames(table)[colnames(table) == "OBS_VALUE"] <- value
return(table)
})
# Optionally, assign names to the list elements based on 'na_item' values
names(list_of_tables) <- unique_values
# Example of accessing the resulting tables
# To access the table for a specific 'na_item' value, e.g., "value1":
t_value1 <- list_of_tables[["value1"]]
View(list_of_tables)
View(list_of_tables[["Output"]])
t_economic_values <- subset(t_economic_values, select = c(nace_r2, na_item, geo, TIME_PERIOD, OBS_VALUE))
# Get unique values in the 'na_item' column
unique_values <- unique(t_economic_values$na_item)
# Create a list to store the resulting data frames
list_of_tables <- lapply(unique_values, function(value) {
# Filter the rows where 'na_item' equals the current value
table <- subset(t_economic_values, na_item == value)
# Rename the 'OBS_VALUE' column to the current 'na_item' value
colnames(table)[colnames(table) == "OBS_VALUE"] <- value
return(table)
})
# Optionally, assign names to the list elements based on 'na_item' values
names(list_of_tables) <- unique_values
# Example of accessing the resulting tables
# To access the table for a specific 'na_item' value, e.g., "value1":
t_value1 <- list_of_tables[["value1"]]
View(list_of_tables)
# Subset the relevant columns
t_economic_values <- subset(t_economic_values, select = c(nace_r2, na_item, geo, TIME_PERIOD, OBS_VALUE))
# Get unique values in the 'na_item' column
unique_values <- unique(t_economic_values$na_item)
# Create separate tables for each unique 'na_item' value
for (value in unique_values) {
# Filter the rows where 'na_item' equals the current value
table <- subset(t_economic_values, na_item == value)
# Rename the 'OBS_VALUE' column to the current 'na_item' value
colnames(table)[colnames(table) == "OBS_VALUE"] <- value
# Assign the table to a new variable dynamically
assign(paste("t_", value, sep = ""), table)
}
View(`t_Consumption of fixed capital`)
# Subset the relevant columns
t_economic_values <- subset(t_economic_values, select = c(nace_r2, na_item, geo, TIME_PERIOD, OBS_VALUE))
names(t_economic_values)[names(t_economic_values) == "geo"] <- "Country"
names(t_economic_values)[names(t_economic_values) == "TIME_PERIOD"] <- "Year"
# Get unique values in the 'na_item' column
unique_values <- unique(t_economic_values$na_item)
# Create separate tables for each unique 'na_item' value
for (value in unique_values) {
# Filter the rows where 'na_item' equals the current value
table <- subset(t_economic_values, na_item == value)
# Rename the 'OBS_VALUE' column to the current 'na_item' value
colnames(table)[colnames(table) == "OBS_VALUE"] <- value
# Assign the table to a new variable dynamically
assign(paste("t_", value, sep = ""), table)
}
# Now you have separate tables like t_GDP, t_Unemployment, etc.
list_of_tables[["value1"]]
View(`t_Consumption of fixed capital`)
View(`t_Consumption of fixed capital`)
`t_Consumption of fixed capital` <- -c(na_item)
# Subset the relevant columns
t_economic_values <- subset(t_economic_values, select = c(nace_r2, na_item, geo, TIME_PERIOD, OBS_VALUE))
names(t_economic_values)[names(t_economic_values) == "geo"] <- "Country"
names(t_economic_values)[names(t_economic_values) == "TIME_PERIOD"] <- "Year"
# Get unique values in the 'na_item' column
unique_values <- unique(t_economic_values$na_item)
# Create separate tables for each unique 'na_item' value
for (value in unique_values) {
# Filter the rows where 'na_item' equals the current value
table <- subset(t_economic_values, na_item == value)
# Rename the 'OBS_VALUE' column to the current 'na_item' value
colnames(table)[colnames(table) == "OBS_VALUE"] <- value
# Drop the 'na_item' column
table$na_item <- NULL
# Assign the table to a new variable dynamically
assign(paste("t_", value, sep = ""), table)
}
# Now you have separate tables like t_GDP, t_Unemployment, etc.
list_of_tables[["value1"]]
View(`t_Consumption of fixed capital`)
View(t_Output)
View(`t_Intermediate consumption`)
View(t_wages_2)
View(t_registrations)
library(dplyr)
# Perform the full join across all tables
combined_data <- t_Consumption_of_fixed_capital %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_Intermediate_consumption, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
# View the combined data
head(combined_data)
# Perform the full join across all tables
combined_data <- t_Consumption_of_fixed_capital %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_Intermediate_consumption, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
library(dplyr)
# Perform the full join across all tables
combined_data <- t_Consumption_of_fixed_capital %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_Intermediate_consumption, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
# Perform the full join across all tables
combined_data <- `t_Consumption of fixed capital` %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_Intermediate_consumption, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
# Perform the full join across all tables
combined_data <- `t_Consumption of fixed capital` %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(`t_Intermediate consumption`, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
# View the combined data
head(combined_data)
View(combined_data)
write.csv(combined_data, "C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\combined_data.csv", row.names = FALSE)
write.csv(combined_data, "C:\Users\maidi\OneDrive\Desktop\OneDrive - Università degli Studi di Milano\causal_inference_project\Data3\combined_data.csv", row.names = FALSE)
write.csv(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv", row.names = FALSE)
install.packages("haven")  # Run this if you haven't installed the package yet
library(haven)  # Load the package
library(haven)  # Load the package
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
rlang::last_trace()
rlang::last_trace(drop = FALSE)
View(combined_data)
# Rename the problematic column
colnames(combined_data)[colnames(combined_data) == "Real labour productivity per person"] <- "Real labour productivity"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
colnames(combined_data)[colnames(combined_data) == "Consumption of fixed capital"] <- "Consumption of capital"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
# Rename the problematic column
colnames(combined_data)[colnames(combined_data) == "Real labour productivity per person"] <- "real_labour_productivity"
colnames(combined_data)[colnames(combined_data) == "Consumption of fixed capital"] <- "consumption_of_capital"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
View(combined_data)
# Rename the problematic column
names(combined_data)[colnames(combined_data) == "Real labour productivity per person"] <- "real_labour_productivity"
names(combined_data)[colnames(combined_data) == "Consumption of fixed capital"] <- "consumption_of_capital"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
View(combined_data)
# Rename the problematic column
names(combined_data)[colnames(combined_data) == "Real labour productivity per person"] <- "real_labour_productivity"
View(combined_data)
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
# Perform the full join across all tables
combined_data <- `t_Consumption of fixed capital` %>%
full_join(t_Output, by = c("Country", "Year", "nace_r2")) %>%
full_join(`t_Intermediate consumption`, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_wages_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_productivity_2, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_bankruptcy, by = c("Country", "Year", "nace_r2")) %>%
full_join(t_registrations, by = c("Country", "Year", "nace_r2"))
# View the combined data
head(combined_data)
write.csv(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv", row.names = FALSE)
library(haven)  # Load the package
# Rename the problematic column
names(combined_data)[colnames(combined_data) == "Real labour productivity per person"] <- "real_labour_productivity"
names(combined_data)[colnames(combined_data) == "Consumption of fixed capital"] <- "consumption_of_capital"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
names(combined_data)[colnames(combined_data) == "Intermediate consumption"] <- "intermediate_consumption"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
names(combined_data)[colnames(combined_data) == "Wagws and salaries"] <- "wages_and_salaries"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
names(combined_data)[colnames(combined_data) == "Wages and salaries"] <- "wages_and_salaries"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
names(combined_data)[colnames(combined_data) == "Bankruptcy declarations Index"] <- "bankruptcy_declarations_index"
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv")
write.csv(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv", row.names = FALSE)
write.csv(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.csv", row.names = FALSE)
write_dta(combined_data, "C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data3\\combined_data.dta")
View(combined_data)
View(combined_data)
install.packages("xtable")
library(xtable)
install.packages("xtable")
library(xtable)
setwd("C:\\Users\\maidi\\OneDrive\\Desktop\\OneDrive - Università degli Studi di Milano\\causal_inference_project\\Data4")
library(readxl)
library(data.table) # or library(readr)
# Get the list of all files in the directory
files <- list.files(pattern = "\\.(csv|xlsx)$")
# Loop through each file and create separate data frames
for (file in files) {
# Generate a valid variable name for the data frame
df_name <- gsub("\\.|-|\\s", "_", tools::file_path_sans_ext(file))
if (grepl("\\.csv$", file)) {
# Read CSV files
assign(df_name, fread(file)) # Use read_csv(file) if using `readr`
} else if (grepl("\\.xlsx$", file)) {
# Read XLSX files
assign(df_name, read_excel(file))
}
}
# Check the created data frames
ls()
library(dplyr)
# Rename specific columns
tradeunion_density <- tradeunion_density %>%
rename(
geo = `Reference area`,
)
hh_index <- hh_index %>%
rename(
TIME_PERIOD = Year,
geo = "Country Name"
)
# List all data frames in the environment
dfs <- ls()
# Loop through each object and keep only the specified columns, and rename 'OBS_VALUE' column
for (df_name in dfs) {
# Check if the object is a data frame
if (is.data.frame(get(df_name))) {
# Use tryCatch to handle potential errors
tryCatch({
# Get the data frame
df <- get(df_name)
# Keep only the specified columns: 'geo', 'OBS_VALUE', and 'TIME_PERIOD'
df <- df[, c("geo", "OBS_VALUE", "TIME_PERIOD"), drop = FALSE]
# Rename 'OBS_VALUE' column to the name of the data frame
colnames(df)[colnames(df) == "OBS_VALUE"] <- df_name
# Assign the modified data frame back to the original name
assign(df_name, df)
}, error = function(e) {
# Print the name of the data frame that caused the error
cat("Error in data frame:", df_name, "\n")
cat("Error message:", conditionMessage(e), "\n")
})
}
}
# Get the list of data frame names in the environment
dfs <- ls()
# Initialize an empty list to store the NA counts for each data frame
na_counts <- list()
# Loop through each object in the environment
for (df_name in dfs) {
# Check if the object is a data frame
if (is.data.frame(get(df_name))) {
# Get the data frame
df <- get(df_name)
# Count the number of NA values in each column of the data frame
na_count <- colSums(is.na(df))
# Store the result in the list with the data frame's name as the key
na_counts[[df_name]] <- na_count
}
}
productivity_pp <- productivity_pp %>%
arrange(geo, TIME_PERIOD) %>%
group_by(geo) %>%
mutate(
productivity_1 = lag(productivity_pp, n = 1),
productivity_2 = lag(productivity_pp, n = 2)
) %>%
ungroup()
# Filter out countries with no value for 2020
hicp <- hicp %>%
group_by(geo) %>%
filter(any(TIME_PERIOD == 2020)) %>% # Keep only groups with 2020 data
ungroup()
# Rebase the HICP and replace the original column
hicp <- hicp %>%
group_by(geo) %>%
mutate(
base_value_2020 = hicp[TIME_PERIOD == 2020], # Extract 2020 index
hicp = (hicp / base_value_2020) * 100        # Rebase and overwrite
) %>%
select(-base_value_2020) %>% # Drop the intermediate column
ungroup()
# View the updated dataframe
print(hicp)
# Function to merge and adjust wages
adjust_wages_with_hicp <- function(wages_df, hicp_df) {
# Merge dataframes on geo and TIME_PERIOD
merged_df <- wages_df %>%
left_join(hicp_df, by = c("geo", "TIME_PERIOD"))
# Calculate reference HICP (2015 base)
ref_hicp <- merged_df %>%
filter(TIME_PERIOD == "2015") %>%
pull(hicp) %>%
first()
# Adjust wages
adjusted_df <- merged_df %>%
mutate(
adjusted_wages = wages_per_h_worked * (ref_hicp / hicp),
real_wage_change_pct = ((adjusted_wages - wages_per_h_worked) / wages_per_h_worked) * 100
)
return(adjusted_df)
}
# Usage example
wages_per_h_worked <- adjust_wages_with_hicp(wages_per_h_worked, hicp)
wages_per_h_worked <- wages_per_h_worked %>% select(-c(hicp, wages_per_h_worked, real_wage_change_pct))
# List of dataframes to join
df_list <- list(wages_per_h_worked, hicp, business_investment, low_education, middle_education, high_education,
hh_index,partime_contracts, productivity_pp, realgdp_pc,
tradeunion_density, training_education_l4w, unemployment)
# Perform the left join
result_df <- wages_per_h_worked
# Iteratively join each dataframe
for (df in df_list) {
result_df <- merge(result_df, df, by = c("geo", "TIME_PERIOD"), all.x = TRUE)
}
# Count NA values for each column in the resulting dataframe
na_count <- sapply(result_df, function(x) sum(is.na(x)))
# Print the NA count
print(na_count)
result_df_clean <- na.omit(result_df)
unique_geo_count <- n_distinct(result_df_clean$geo)
unique_geo_count
result_df_clean <- result_df_clean %>% select(-adjusted_wages.x)
result_df_clean <- result_df_clean %>%
rename(
hourly_wages = adjusted_wages.y,
year = TIME_PERIOD
)
#write.csv(result_df_clean, "merged1.csv", row.names = FALSE)
# Save as Stata format (requires haven package)
#library(haven)
#write_dta(result_df_clean, "merged1.dta")
install.packages("xtable")
library(xtable)
View(result_df_clean)
latex_table <- xtable(result_df_clean)
# Print LaTeX code for the table
print(latex_table)
install.packages("stargazer")
library(stargazer)
library(stargazer)
stargazer(result_df_clean, type = "latex", summary = TRUE, title = "Descriptive Statistics", digits = 2)
columns(result_df_clean)
column(result_df_clean)
colnames(result_df_clean)
